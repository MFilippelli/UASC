{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook carries out Naive Bayes classfication on the dataset where the model is trained and validated on data from Paris but tested on data from London."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean0</th>\n",
       "      <th>mean1</th>\n",
       "      <th>mean2</th>\n",
       "      <th>mean3</th>\n",
       "      <th>mean4</th>\n",
       "      <th>mean5</th>\n",
       "      <th>mean6</th>\n",
       "      <th>mean7</th>\n",
       "      <th>mean8</th>\n",
       "      <th>mean9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_diff11</th>\n",
       "      <th>var_diff12</th>\n",
       "      <th>var_diff13</th>\n",
       "      <th>var_diff14</th>\n",
       "      <th>var_diff15</th>\n",
       "      <th>var_diff16</th>\n",
       "      <th>var_diff17</th>\n",
       "      <th>var_diff18</th>\n",
       "      <th>var_diff19</th>\n",
       "      <th>scenes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.575796</td>\n",
       "      <td>0.717401</td>\n",
       "      <td>0.539698</td>\n",
       "      <td>-1.062370</td>\n",
       "      <td>0.191049</td>\n",
       "      <td>-1.723536</td>\n",
       "      <td>-1.194319</td>\n",
       "      <td>0.053656</td>\n",
       "      <td>-0.209370</td>\n",
       "      <td>-0.200844</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.655437</td>\n",
       "      <td>-0.839057</td>\n",
       "      <td>-0.300258</td>\n",
       "      <td>-0.830228</td>\n",
       "      <td>-0.783522</td>\n",
       "      <td>-0.736217</td>\n",
       "      <td>-0.683096</td>\n",
       "      <td>-0.866754</td>\n",
       "      <td>-0.571898</td>\n",
       "      <td>tubestation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.626746</td>\n",
       "      <td>1.382491</td>\n",
       "      <td>0.447212</td>\n",
       "      <td>-1.766357</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>2.536803</td>\n",
       "      <td>0.380988</td>\n",
       "      <td>1.120369</td>\n",
       "      <td>3.892846</td>\n",
       "      <td>4.094601</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.906597</td>\n",
       "      <td>-0.561817</td>\n",
       "      <td>-0.990822</td>\n",
       "      <td>-0.910512</td>\n",
       "      <td>-0.770320</td>\n",
       "      <td>-1.019891</td>\n",
       "      <td>-1.231433</td>\n",
       "      <td>-0.857304</td>\n",
       "      <td>-0.888658</td>\n",
       "      <td>train-ter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.484043</td>\n",
       "      <td>0.597128</td>\n",
       "      <td>1.028187</td>\n",
       "      <td>-1.412017</td>\n",
       "      <td>1.534679</td>\n",
       "      <td>0.511047</td>\n",
       "      <td>1.286969</td>\n",
       "      <td>0.967864</td>\n",
       "      <td>-0.259907</td>\n",
       "      <td>0.790211</td>\n",
       "      <td>...</td>\n",
       "      <td>1.939481</td>\n",
       "      <td>2.260830</td>\n",
       "      <td>2.335424</td>\n",
       "      <td>2.172651</td>\n",
       "      <td>2.198847</td>\n",
       "      <td>2.151799</td>\n",
       "      <td>1.910007</td>\n",
       "      <td>1.362777</td>\n",
       "      <td>1.451639</td>\n",
       "      <td>bus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.308431</td>\n",
       "      <td>-0.005826</td>\n",
       "      <td>-0.932353</td>\n",
       "      <td>0.143836</td>\n",
       "      <td>-0.619640</td>\n",
       "      <td>0.029328</td>\n",
       "      <td>-0.851747</td>\n",
       "      <td>-0.587147</td>\n",
       "      <td>0.131899</td>\n",
       "      <td>-0.957469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.320351</td>\n",
       "      <td>0.050667</td>\n",
       "      <td>-0.057665</td>\n",
       "      <td>0.239617</td>\n",
       "      <td>0.260419</td>\n",
       "      <td>0.668990</td>\n",
       "      <td>0.290236</td>\n",
       "      <td>0.469636</td>\n",
       "      <td>0.520772</td>\n",
       "      <td>market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.846697</td>\n",
       "      <td>-1.260525</td>\n",
       "      <td>1.779260</td>\n",
       "      <td>0.112545</td>\n",
       "      <td>0.020945</td>\n",
       "      <td>0.628017</td>\n",
       "      <td>0.523070</td>\n",
       "      <td>1.356682</td>\n",
       "      <td>1.079687</td>\n",
       "      <td>0.648798</td>\n",
       "      <td>...</td>\n",
       "      <td>3.062474</td>\n",
       "      <td>0.293887</td>\n",
       "      <td>3.250679</td>\n",
       "      <td>-0.146490</td>\n",
       "      <td>2.591120</td>\n",
       "      <td>-0.208007</td>\n",
       "      <td>0.856651</td>\n",
       "      <td>0.327243</td>\n",
       "      <td>-0.246140</td>\n",
       "      <td>train-ter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean0     mean1     mean2     mean3     mean4     mean5     mean6  \\\n",
       "0  0.575796  0.717401  0.539698 -1.062370  0.191049 -1.723536 -1.194319   \n",
       "1 -0.626746  1.382491  0.447212 -1.766357  0.009479  2.536803  0.380988   \n",
       "2 -0.484043  0.597128  1.028187 -1.412017  1.534679  0.511047  1.286969   \n",
       "3  0.308431 -0.005826 -0.932353  0.143836 -0.619640  0.029328 -0.851747   \n",
       "4 -1.846697 -1.260525  1.779260  0.112545  0.020945  0.628017  0.523070   \n",
       "\n",
       "      mean7     mean8     mean9     ...       var_diff11  var_diff12  \\\n",
       "0  0.053656 -0.209370 -0.200844     ...        -0.655437   -0.839057   \n",
       "1  1.120369  3.892846  4.094601     ...        -0.906597   -0.561817   \n",
       "2  0.967864 -0.259907  0.790211     ...         1.939481    2.260830   \n",
       "3 -0.587147  0.131899 -0.957469     ...         0.320351    0.050667   \n",
       "4  1.356682  1.079687  0.648798     ...         3.062474    0.293887   \n",
       "\n",
       "   var_diff13  var_diff14  var_diff15  var_diff16  var_diff17  var_diff18  \\\n",
       "0   -0.300258   -0.830228   -0.783522   -0.736217   -0.683096   -0.866754   \n",
       "1   -0.990822   -0.910512   -0.770320   -1.019891   -1.231433   -0.857304   \n",
       "2    2.335424    2.172651    2.198847    2.151799    1.910007    1.362777   \n",
       "3   -0.057665    0.239617    0.260419    0.668990    0.290236    0.469636   \n",
       "4    3.250679   -0.146490    2.591120   -0.208007    0.856651    0.327243   \n",
       "\n",
       "   var_diff19       scenes  \n",
       "0   -0.571898  tubestation  \n",
       "1   -0.888658    train-ter  \n",
       "2    1.451639          bus  \n",
       "3    0.520772       market  \n",
       "4   -0.246140    train-ter  \n",
       "\n",
       "[5 rows x 161 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the labelled datasets\n",
    "\n",
    "train = pd.read_csv('Data1/Data1_train.csv')\n",
    "validation = pd.read_csv('Data1/Data1_validation.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Concatenating the 2 sets to form ONE TRAINING SET\n",
    "trainCombined = pd.concat([train, validation], axis=0)\n",
    "\n",
    "# Splitting train and test to take the first 10 features only\n",
    "trainSet = trainCombined.iloc[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tubestation', 'train-ter', 'bus', 'market', 'restaurant',\n",
       "       'busystreet', 'quietstreet'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Not required, just getting the names\n",
    "\n",
    "train.scenes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     tubestation\n",
       "1       train-ter\n",
       "2             bus\n",
       "3          market\n",
       "4       train-ter\n",
       "5     tubestation\n",
       "6       train-ter\n",
       "7             bus\n",
       "8      restaurant\n",
       "9      busystreet\n",
       "10     busystreet\n",
       "11     busystreet\n",
       "12    tubestation\n",
       "13     busystreet\n",
       "14    tubestation\n",
       "Name: scenes, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the corresponding Y scenes(text)\n",
    "\n",
    "Y_labels = trainCombined.scenes\n",
    "Y_labels[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The function that assigns numbers to our categories\n",
    "\n",
    "def numericLabels(x):\n",
    "     return {\n",
    "        ourLabels[0]: 1,\n",
    "        ourLabels[1]: 2,\n",
    "        ourLabels[2]: 3,\n",
    "        ourLabels[3]: 4,\n",
    "        ourLabels[4]: 5,\n",
    "        'unknown': 6,\n",
    "    }[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The function that assigns numerical values to our labels\n",
    "ourLabels = ['tubestation', 'quietstreet', 'busystreet', 'restaurant', 'market']\n",
    "\n",
    "def manageLabels(labelsText, labelsNum):\n",
    "    i = 0;\n",
    "    while i < labelsText.size:\n",
    "        if labelsText[i] not in ourLabels:\n",
    "            labelsText.replace(labelsText[i],'unknown',inplace=True)\n",
    "        labelsNum[i] = numericLabels(labelsText[i])\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " **** For 70/30 data split ratio **** : \n",
      "\n",
      "We successfully predict 100% of data using linear kernel for the training data\n",
      "We successfully predict 100% of data using poly kernel for the training data\n",
      "We successfully predict 100% of data using rbf kernel for the training data\n",
      "\n",
      " With C = 1.5\n",
      "We successfully predict 84.4497607656% of data using linear kernel for the test data\n",
      "We successfully predict 85.1674641148% of data using poly kernel for the test data\n",
      "We successfully predict 91.1483253589% of data using rbf kernel for the test data\n",
      "\n",
      " With C = 2.5\n",
      "We successfully predict 84.9282296651% of data using linear kernel for the test data\n",
      "We successfully predict 88.5167464115% of data using poly kernel for the test data\n",
      "We successfully predict 92.8229665072% of data using rbf kernel for the test data\n",
      "\n",
      "\n",
      " **** For 72/28 data split ratio **** : \n",
      "\n",
      "We successfully predict 100% of data using linear kernel for the training data\n",
      "We successfully predict 100% of data using poly kernel for the training data\n",
      "We successfully predict 100% of data using rbf kernel for the training data\n",
      "\n",
      " With C = 1.5\n",
      "We successfully predict 85.3846153846% of data using linear kernel for the test data\n",
      "We successfully predict 85.641025641% of data using poly kernel for the test data\n",
      "We successfully predict 91.2820512821% of data using rbf kernel for the test data\n",
      "\n",
      " With C = 2.5\n",
      "We successfully predict 86.1538461538% of data using linear kernel for the test data\n",
      "We successfully predict 88.7179487179% of data using poly kernel for the test data\n",
      "We successfully predict 93.0769230769% of data using rbf kernel for the test data\n",
      "\n",
      "\n",
      " **** For 74/26 data split ratio **** : \n",
      "\n",
      "We successfully predict 100% of data using linear kernel for the training data\n",
      "We successfully predict 100% of data using poly kernel for the training data\n",
      "We successfully predict 100% of data using rbf kernel for the training data\n",
      "\n",
      " With C = 1.5\n",
      "We successfully predict 84.8066298343% of data using linear kernel for the test data\n",
      "We successfully predict 84.8066298343% of data using poly kernel for the test data\n",
      "We successfully predict 91.1602209945% of data using rbf kernel for the test data\n",
      "\n",
      " With C = 2.5\n",
      "We successfully predict 84.5303867403% of data using linear kernel for the test data\n",
      "We successfully predict 87.5690607735% of data using poly kernel for the test data\n",
      "We successfully predict 93.0939226519% of data using rbf kernel for the test data\n",
      "\n",
      "\n",
      " **** For 76/24 data split ratio **** : \n",
      "\n",
      "We successfully predict 100% of data using linear kernel for the training data\n",
      "We successfully predict 100% of data using poly kernel for the training data\n",
      "We successfully predict 100% of data using rbf kernel for the training data\n",
      "\n",
      " With C = 1.5\n",
      "We successfully predict 83.8323353293% of data using linear kernel for the test data\n",
      "We successfully predict 85.0299401198% of data using poly kernel for the test data\n",
      "We successfully predict 91.9161676647% of data using rbf kernel for the test data\n",
      "\n",
      " With C = 2.5\n",
      "We successfully predict 85.9281437126% of data using linear kernel for the test data\n",
      "We successfully predict 87.125748503% of data using poly kernel for the test data\n",
      "We successfully predict 93.7125748503% of data using rbf kernel for the test data\n",
      "\n",
      "\n",
      " **** For 78/22 data split ratio **** : \n",
      "\n",
      "We successfully predict 100% of data using linear kernel for the training data\n",
      "We successfully predict 100% of data using poly kernel for the training data\n",
      "We successfully predict 100% of data using rbf kernel for the training data\n",
      "\n",
      " With C = 1.5\n",
      "We successfully predict 83.0618892508% of data using linear kernel for the test data\n",
      "We successfully predict 82.7361563518% of data using poly kernel for the test data\n",
      "We successfully predict 91.5309446254% of data using rbf kernel for the test data\n",
      "\n",
      " With C = 2.5\n",
      "We successfully predict 85.016286645% of data using linear kernel for the test data\n",
      "We successfully predict 86.319218241% of data using poly kernel for the test data\n",
      "We successfully predict 92.8338762215% of data using rbf kernel for the test data\n",
      "\n",
      "\n",
      " **** For 80/20 data split ratio **** : \n",
      "\n",
      "We successfully predict 100% of data using linear kernel for the training data\n",
      "We successfully predict 100% of data using poly kernel for the training data\n",
      "We successfully predict 100% of data using rbf kernel for the training data\n",
      "\n",
      " With C = 1.5\n",
      "We successfully predict 83.5125448029% of data using linear kernel for the test data\n",
      "We successfully predict 80.6451612903% of data using poly kernel for the test data\n",
      "We successfully predict 89.9641577061% of data using rbf kernel for the test data\n",
      "\n",
      " With C = 2.5\n",
      "We successfully predict 85.3046594982% of data using linear kernel for the test data\n",
      "We successfully predict 85.3046594982% of data using poly kernel for the test data\n",
      "We successfully predict 92.1146953405% of data using rbf kernel for the test data\n"
     ]
    }
   ],
   "source": [
    "validationSize = [0.30, 0.28, 0.26, 0.24, 0.22, 0.20]\n",
    "softMargin = [1.5, 2.5]\n",
    "\n",
    "for i in validationSize:\n",
    "    #splitting the dataset\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(trainSet, Y_labels, test_size=i, random_state=2891)\n",
    "    \n",
    "    #resetting indices for the labelled sets so that they work with the pre written functions\n",
    "    Y_train.reset_index(drop=True, inplace=True)\n",
    "    Y_test.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    \n",
    "    #Converting the labels to numerical values\n",
    "    Y_train1 = Y_train\n",
    "    Y_test1 = Y_test\n",
    "    manageLabels(Y_train, Y_train1)\n",
    "    manageLabels(Y_test, Y_test1)\n",
    "    \n",
    "    #converting type of Y to int\n",
    "    Y_train1 = Y_train1.astype('int64')\n",
    "    Y_test1 = Y_test1.astype('int64')\n",
    "    \n",
    "    #Readability shenanigans\n",
    "    testing = 100 * i\n",
    "    training = 100 - testing\n",
    "    print '\\n\\n **** For %d/%d data split ratio **** : \\n' %(training, testing)\n",
    "    \n",
    "    #Train the model (Poly with degree=3)\n",
    "    for kernel in ('linear', 'poly', 'rbf'):\n",
    "        clf = svm.SVC(kernel=kernel, C=2.5, degree=3)\n",
    "        clf.fit(X_train, Y_train1)\n",
    "        print \"We successfully predict {0}% of data using {1} kernel for the training data\".format(100-abs(clf.predict(X_train)-Y_train1).sum()/len(Y_train1), kernel)\n",
    "    \n",
    "    #Fit the model (Poly with degree=3, C=1.5 and 2.5)\n",
    "    for c in softMargin:\n",
    "        print '\\n With C = %.1f' %c   \n",
    "        for kernel in ('linear', 'poly', 'rbf'):\n",
    "            clf = svm.SVC(kernel=kernel, C=c, degree=3)\n",
    "            clf.fit(X_test, Y_test1)\n",
    "            correct=1.0*(clf.predict(X_test)==np.asarray(Y_test1)).sum()/len(Y_test1)\n",
    "            print \"We successfully predict {0}% of data using {1} kernel for the test data\".format((correct)*100, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since SVM performed best on the SOC data, the final test set is used on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('Data1/Data1_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testSet = test.iloc[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bus', 'busystreet', 'office', 'openairmarket', 'park',\n",
       "       'quietstreet', 'restaurant', 'supermarket', 'tube', 'tubestation'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.scenes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            bus\n",
       "1            bus\n",
       "2            bus\n",
       "3            bus\n",
       "4            bus\n",
       "5            bus\n",
       "6            bus\n",
       "7            bus\n",
       "8            bus\n",
       "9            bus\n",
       "10    busystreet\n",
       "11    busystreet\n",
       "12    busystreet\n",
       "13    busystreet\n",
       "14    busystreet\n",
       "Name: scenes, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_labels = test.scenes\n",
    "Y_labels[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Neil\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "Y_labels.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#Converting the labels to numerical values\n",
    "Y_test = Y_labels\n",
    "manageLabels(Y_test, Y_labels)\n",
    "\n",
    "#converting type of Y to int\n",
    "Y_test = Y_test.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We successfully predict 37.5% of data using poly kernel for the test data\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='poly', C=2.5, degree=3)\n",
    "clf.fit(X_train, Y_train1)\n",
    "correct=1.0*(clf.predict(testSet)==np.asarray(Y_test)).sum()/len(Y_test)\n",
    "print \"We successfully predict {0}% of data using {1} kernel for the test data\".format((correct)*100, 'poly')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
