{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean0</th>\n",
       "      <th>mean1</th>\n",
       "      <th>mean2</th>\n",
       "      <th>mean3</th>\n",
       "      <th>mean4</th>\n",
       "      <th>mean5</th>\n",
       "      <th>mean6</th>\n",
       "      <th>mean7</th>\n",
       "      <th>mean8</th>\n",
       "      <th>mean9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_diff11</th>\n",
       "      <th>var_diff12</th>\n",
       "      <th>var_diff13</th>\n",
       "      <th>var_diff14</th>\n",
       "      <th>var_diff15</th>\n",
       "      <th>var_diff16</th>\n",
       "      <th>var_diff17</th>\n",
       "      <th>var_diff18</th>\n",
       "      <th>var_diff19</th>\n",
       "      <th>scenes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.093323</td>\n",
       "      <td>-0.399723</td>\n",
       "      <td>0.783561</td>\n",
       "      <td>-2.520351</td>\n",
       "      <td>2.564316</td>\n",
       "      <td>-0.604616</td>\n",
       "      <td>1.020544</td>\n",
       "      <td>1.818084</td>\n",
       "      <td>-2.152912</td>\n",
       "      <td>1.866948</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.980404</td>\n",
       "      <td>-0.940530</td>\n",
       "      <td>-1.060487</td>\n",
       "      <td>-0.915270</td>\n",
       "      <td>-0.933561</td>\n",
       "      <td>-1.192804</td>\n",
       "      <td>-1.120846</td>\n",
       "      <td>-1.367337</td>\n",
       "      <td>-1.184519</td>\n",
       "      <td>train-ter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.076053</td>\n",
       "      <td>1.165681</td>\n",
       "      <td>0.960745</td>\n",
       "      <td>-1.856342</td>\n",
       "      <td>0.366469</td>\n",
       "      <td>1.074824</td>\n",
       "      <td>0.338721</td>\n",
       "      <td>1.890659</td>\n",
       "      <td>3.694118</td>\n",
       "      <td>2.813581</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.824649</td>\n",
       "      <td>-0.925210</td>\n",
       "      <td>-0.656642</td>\n",
       "      <td>-0.723337</td>\n",
       "      <td>-0.911938</td>\n",
       "      <td>-0.838659</td>\n",
       "      <td>-0.662626</td>\n",
       "      <td>-0.954069</td>\n",
       "      <td>-0.782338</td>\n",
       "      <td>train-ter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.855206</td>\n",
       "      <td>1.212459</td>\n",
       "      <td>-0.488913</td>\n",
       "      <td>0.914367</td>\n",
       "      <td>-0.056152</td>\n",
       "      <td>-0.089688</td>\n",
       "      <td>1.160520</td>\n",
       "      <td>0.783487</td>\n",
       "      <td>0.425175</td>\n",
       "      <td>-0.174028</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.758511</td>\n",
       "      <td>-0.884370</td>\n",
       "      <td>-1.231002</td>\n",
       "      <td>-0.600003</td>\n",
       "      <td>-0.559877</td>\n",
       "      <td>-0.837631</td>\n",
       "      <td>-0.818048</td>\n",
       "      <td>-0.670121</td>\n",
       "      <td>-0.492715</td>\n",
       "      <td>busystreet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.347927</td>\n",
       "      <td>-1.241400</td>\n",
       "      <td>-0.085663</td>\n",
       "      <td>1.107282</td>\n",
       "      <td>0.342155</td>\n",
       "      <td>-0.151280</td>\n",
       "      <td>-0.556604</td>\n",
       "      <td>0.207628</td>\n",
       "      <td>-0.366518</td>\n",
       "      <td>-0.758259</td>\n",
       "      <td>...</td>\n",
       "      <td>1.683114</td>\n",
       "      <td>1.931850</td>\n",
       "      <td>1.657565</td>\n",
       "      <td>1.608029</td>\n",
       "      <td>1.631192</td>\n",
       "      <td>1.646374</td>\n",
       "      <td>1.472824</td>\n",
       "      <td>1.409602</td>\n",
       "      <td>1.616908</td>\n",
       "      <td>restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.752063</td>\n",
       "      <td>-1.192575</td>\n",
       "      <td>-0.296607</td>\n",
       "      <td>-0.540139</td>\n",
       "      <td>0.113057</td>\n",
       "      <td>-1.612495</td>\n",
       "      <td>-0.691072</td>\n",
       "      <td>-0.810711</td>\n",
       "      <td>-1.709526</td>\n",
       "      <td>-0.551167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032911</td>\n",
       "      <td>0.433523</td>\n",
       "      <td>0.657787</td>\n",
       "      <td>0.347634</td>\n",
       "      <td>0.597555</td>\n",
       "      <td>0.455884</td>\n",
       "      <td>0.332098</td>\n",
       "      <td>0.407437</td>\n",
       "      <td>0.221523</td>\n",
       "      <td>market</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean0     mean1     mean2     mean3     mean4     mean5     mean6  \\\n",
       "0  0.093323 -0.399723  0.783561 -2.520351  2.564316 -0.604616  1.020544   \n",
       "1  0.076053  1.165681  0.960745 -1.856342  0.366469  1.074824  0.338721   \n",
       "2  0.855206  1.212459 -0.488913  0.914367 -0.056152 -0.089688  1.160520   \n",
       "3  0.347927 -1.241400 -0.085663  1.107282  0.342155 -0.151280 -0.556604   \n",
       "4  0.752063 -1.192575 -0.296607 -0.540139  0.113057 -1.612495 -0.691072   \n",
       "\n",
       "      mean7     mean8     mean9     ...      var_diff11  var_diff12  \\\n",
       "0  1.818084 -2.152912  1.866948     ...       -0.980404   -0.940530   \n",
       "1  1.890659  3.694118  2.813581     ...       -0.824649   -0.925210   \n",
       "2  0.783487  0.425175 -0.174028     ...       -0.758511   -0.884370   \n",
       "3  0.207628 -0.366518 -0.758259     ...        1.683114    1.931850   \n",
       "4 -0.810711 -1.709526 -0.551167     ...        0.032911    0.433523   \n",
       "\n",
       "   var_diff13  var_diff14  var_diff15  var_diff16  var_diff17  var_diff18  \\\n",
       "0   -1.060487   -0.915270   -0.933561   -1.192804   -1.120846   -1.367337   \n",
       "1   -0.656642   -0.723337   -0.911938   -0.838659   -0.662626   -0.954069   \n",
       "2   -1.231002   -0.600003   -0.559877   -0.837631   -0.818048   -0.670121   \n",
       "3    1.657565    1.608029    1.631192    1.646374    1.472824    1.409602   \n",
       "4    0.657787    0.347634    0.597555    0.455884    0.332098    0.407437   \n",
       "\n",
       "   var_diff19      scenes  \n",
       "0   -1.184519   train-ter  \n",
       "1   -0.782338   train-ter  \n",
       "2   -0.492715  busystreet  \n",
       "3    1.616908  restaurant  \n",
       "4    0.221523      market  \n",
       "\n",
       "[5 rows x 161 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the labelled datasets\n",
    "\n",
    "train = pd.read_csv('Data2/Data2_train.csv')\n",
    "validation = pd.read_csv('Data2/Data2_validation.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Concatenating the 2 sets to form ONE TRAINING SET\n",
    "trainCombined = pd.concat([train, validation], axis=0)\n",
    "\n",
    "# Splitting train and test to take the first 10 features only\n",
    "trainSet = trainCombined.iloc[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['train-ter', 'busystreet', 'restaurant', 'market', 'quietstreet',\n",
       "       'bus', 'tubestation', 'tube', 'supermarket', 'park', 'office',\n",
       "       'openairmarket'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Not required, just getting the names\n",
    "\n",
    "train.scenes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       train-ter\n",
       "1       train-ter\n",
       "2      busystreet\n",
       "3      restaurant\n",
       "4          market\n",
       "5      busystreet\n",
       "6          market\n",
       "7       train-ter\n",
       "8          market\n",
       "9      restaurant\n",
       "10     restaurant\n",
       "11      train-ter\n",
       "12     busystreet\n",
       "13    quietstreet\n",
       "14            bus\n",
       "Name: scenes, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the corresponding Y scenes(text)\n",
    "\n",
    "Y_labels = trainCombined.scenes\n",
    "Y_labels[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The function that assigns numbers to our categories\n",
    "\n",
    "def numericLabels(x):\n",
    "     return {\n",
    "        ourLabels[0]: 1,\n",
    "        ourLabels[1]: 2,\n",
    "        ourLabels[2]: 3,\n",
    "        ourLabels[3]: 4,\n",
    "        ourLabels[4]: 5,\n",
    "        ourLabels[5]: 5,\n",
    "        'unknown': 6,\n",
    "    }[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The function that assigns numerical values to our labels\n",
    "ourLabels = ['tubestation', 'quietstreet', 'busystreet', 'restaurant', 'market', 'openairmarket']\n",
    "\n",
    "def manageLabels(labelsText, labelsNum):\n",
    "    i = 0;\n",
    "    while i < labelsText.size:\n",
    "        if labelsText[i] not in ourLabels:\n",
    "            labelsText.replace(labelsText[i],'unknown',inplace=True)\n",
    "        labelsNum[i] = numericLabels(labelsText[i])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " **** For 70/30 data split ratio **** : \n",
      "\n",
      "We successfully predict 100% of data using linear kernel for the training data\n",
      "We successfully predict 100% of data using poly kernel for the training data\n",
      "We successfully predict 100% of data using rbf kernel for the training data\n",
      "\n",
      " With C = 1.5\n",
      "We successfully predict 77.358490566% of data using linear kernel for the test data\n",
      "We successfully predict 78.3018867925% of data using poly kernel for the test data\n",
      "We successfully predict 85.8490566038% of data using rbf kernel for the test data\n",
      "\n",
      " With C = 2.5\n",
      "We successfully predict 78.3018867925% of data using linear kernel for the test data\n",
      "We successfully predict 82.0754716981% of data using poly kernel for the test data\n",
      "We successfully predict 90.8805031447% of data using rbf kernel for the test data\n",
      "\n",
      "\n",
      " **** For 72/28 data split ratio **** : \n",
      "\n",
      "We successfully predict 100% of data using linear kernel for the training data\n",
      "We successfully predict 100% of data using poly kernel for the training data\n",
      "We successfully predict 100% of data using rbf kernel for the training data\n",
      "\n",
      " With C = 1.5\n",
      "We successfully predict 76.430976431% of data using linear kernel for the test data\n",
      "We successfully predict 78.1144781145% of data using poly kernel for the test data\n",
      "We successfully predict 85.5218855219% of data using rbf kernel for the test data\n",
      "\n",
      " With C = 2.5\n",
      "We successfully predict 76.7676767677% of data using linear kernel for the test data\n",
      "We successfully predict 82.8282828283% of data using poly kernel for the test data\n",
      "We successfully predict 90.2356902357% of data using rbf kernel for the test data\n",
      "\n",
      "\n",
      " **** For 74/26 data split ratio **** : \n",
      "\n",
      "We successfully predict 100% of data using linear kernel for the training data\n",
      "We successfully predict 100% of data using poly kernel for the training data\n",
      "We successfully predict 100% of data using rbf kernel for the training data\n",
      "\n",
      " With C = 1.5\n",
      "We successfully predict 77.5362318841% of data using linear kernel for the test data\n",
      "We successfully predict 77.8985507246% of data using poly kernel for the test data\n",
      "We successfully predict 85.8695652174% of data using rbf kernel for the test data\n",
      "\n",
      " With C = 2.5\n",
      "We successfully predict 77.5362318841% of data using linear kernel for the test data\n",
      "We successfully predict 81.1594202899% of data using poly kernel for the test data\n",
      "We successfully predict 90.9420289855% of data using rbf kernel for the test data\n",
      "\n",
      "\n",
      " **** For 76/24 data split ratio **** : \n",
      "\n",
      "We successfully predict 100% of data using linear kernel for the training data\n",
      "We successfully predict 100% of data using poly kernel for the training data\n",
      "We successfully predict 100% of data using rbf kernel for the training data\n",
      "\n",
      " With C = 1.5\n",
      "We successfully predict 78.8235294118% of data using linear kernel for the test data\n",
      "We successfully predict 77.6470588235% of data using poly kernel for the test data\n",
      "We successfully predict 85.4901960784% of data using rbf kernel for the test data\n",
      "\n",
      " With C = 2.5\n",
      "We successfully predict 81.568627451% of data using linear kernel for the test data\n",
      "We successfully predict 81.1764705882% of data using poly kernel for the test data\n",
      "We successfully predict 91.3725490196% of data using rbf kernel for the test data\n",
      "\n",
      "\n",
      " **** For 78/22 data split ratio **** : \n",
      "\n",
      "We successfully predict 100% of data using linear kernel for the training data\n",
      "We successfully predict 100% of data using poly kernel for the training data\n",
      "We successfully predict 100% of data using rbf kernel for the training data\n",
      "\n",
      " With C = 1.5\n",
      "We successfully predict 79.8283261803% of data using linear kernel for the test data\n",
      "We successfully predict 78.1115879828% of data using poly kernel for the test data\n",
      "We successfully predict 86.69527897% of data using rbf kernel for the test data\n",
      "\n",
      " With C = 2.5\n",
      "We successfully predict 80.686695279% of data using linear kernel for the test data\n",
      "We successfully predict 81.5450643777% of data using poly kernel for the test data\n",
      "We successfully predict 91.4163090129% of data using rbf kernel for the test data\n",
      "\n",
      "\n",
      " **** For 80/20 data split ratio **** : \n",
      "\n",
      "We successfully predict 100% of data using linear kernel for the training data\n",
      "We successfully predict 100% of data using poly kernel for the training data\n",
      "We successfully predict 100% of data using rbf kernel for the training data\n",
      "\n",
      " With C = 1.5\n",
      "We successfully predict 83.0188679245% of data using linear kernel for the test data\n",
      "We successfully predict 76.8867924528% of data using poly kernel for the test data\n",
      "We successfully predict 87.2641509434% of data using rbf kernel for the test data\n",
      "\n",
      " With C = 2.5\n",
      "We successfully predict 84.9056603774% of data using linear kernel for the test data\n",
      "We successfully predict 82.5471698113% of data using poly kernel for the test data\n",
      "We successfully predict 90.5660377358% of data using rbf kernel for the test data\n"
     ]
    }
   ],
   "source": [
    "validationSize = [0.30, 0.28, 0.26, 0.24, 0.22, 0.20]\n",
    "softMargin = [1.5, 2.5]\n",
    "\n",
    "for i in validationSize:\n",
    "    #splitting the dataset\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(trainSet, Y_labels, test_size=i, random_state=2891)\n",
    "    \n",
    "    #resetting indices for the labelled sets so that they work with the pre written functions\n",
    "    Y_train.reset_index(drop=True, inplace=True)\n",
    "    Y_test.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    \n",
    "    #Converting the labels to numerical values\n",
    "    Y_train1 = Y_train\n",
    "    Y_test1 = Y_test\n",
    "    manageLabels(Y_train, Y_train1)\n",
    "    manageLabels(Y_test, Y_test1)\n",
    "    \n",
    "    #converting type of Y to int\n",
    "    Y_train1 = Y_train1.astype('int64')\n",
    "    Y_test1 = Y_test1.astype('int64')\n",
    "    \n",
    "    #Readability shenanigans\n",
    "    testing = 100 * i\n",
    "    training = 100 - testing\n",
    "    print '\\n\\n **** For %d/%d data split ratio **** : \\n' %(training, testing)\n",
    "    \n",
    "    #Train the model (Poly with degree=3)\n",
    "    for kernel in ('linear', 'poly', 'rbf'):\n",
    "        clf = svm.SVC(kernel=kernel, C=2.5, degree=3)\n",
    "        clf.fit(X_train, Y_train1)\n",
    "        print \"We successfully predict {0}% of data using {1} kernel for the training data\".format(100-abs(clf.predict(X_train)-Y_train1).sum()/len(Y_train1), kernel)\n",
    "    \n",
    "    #Fit the model (Poly with degree=3,, C=1.5 and 2.5)\n",
    "    for c in softMargin:\n",
    "        print '\\n With C = %.1f' %c   \n",
    "        for kernel in ('linear', 'poly', 'rbf'):\n",
    "            clf = svm.SVC(kernel=kernel, C=c, degree=3)\n",
    "            clf.fit(X_test, Y_test1)\n",
    "            correct=1.0*(clf.predict(X_test)==np.asarray(Y_test1)).sum()/len(Y_test1)\n",
    "            print \"We successfully predict {0}% of data using {1} kernel for the test data\".format((correct)*100, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since SVM performed best on the Generalizability data, the final test set is used on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('Data2/Data2_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testSet = test.iloc[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bus', 'busystreet', 'train-ter', 'quietstreet', 'restaurant',\n",
       "       'tube', 'market', 'tubestation', 'office', 'park', 'supermarket',\n",
       "       'openairmarket'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.scenes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             bus\n",
       "1      busystreet\n",
       "2       train-ter\n",
       "3      busystreet\n",
       "4     quietstreet\n",
       "5      restaurant\n",
       "6            tube\n",
       "7          market\n",
       "8     tubestation\n",
       "9             bus\n",
       "10     restaurant\n",
       "11         office\n",
       "12            bus\n",
       "13     busystreet\n",
       "14     busystreet\n",
       "Name: scenes, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_labels = test.scenes\n",
    "Y_labels[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Neil\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "Y_labels.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#Converting the labels to numerical values\n",
    "Y_test = Y_labels\n",
    "manageLabels(Y_test, Y_labels)\n",
    "\n",
    "#converting type of Y to int\n",
    "Y_test = Y_test.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We successfully predict 71.2121212121% of data using poly kernel for the test data\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='poly', C=2.5, degree=3)\n",
    "clf.fit(X_train, Y_train1)\n",
    "correct=1.0*(clf.predict(testSet)==np.asarray(Y_test)).sum()/len(Y_test)\n",
    "print \"We successfully predict {0}% of data using {1} kernel for the test data\".format((correct)*100, 'poly')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
